---
global:
  scrape_interval: 15s  # By default, scrape targets every 15 seconds.
  evaluation_interval: 15s  # By default, scrape targets every 15 seconds.
  # scrape_timeout is set to the global default (10s).


# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:
  - job_name: 'denbi_cloud_project_usage'
    honor_labels: true
    metrics_path: '/federate'

    params:
      'match[]':
        # do not collect any metrics besides the one we are interested in
        - '{job="project_usages",__name__=~"project_.*_usage"}'

    # in production location_id differ from each target but as long as no
    # project runs at multiple locations its fine for development
    static_configs:
      - targets: ['site-a_prometheus_proxy']
        labels:
          location: site-a
          location_id: 8676
      - targets: ['site-b_prometheus_proxy']
        labels:
          location: site-b
          location_id: 8676

    bearer_token: "DontUseThisInProduction"

  - job_name: 'grafana'
    honor_labels: true
    static_configs:
      - targets: ['portal_grafana:3000']

  - job_name: 'credits'
    honor_labels: true
    static_configs:
      - targets: ['portal_credits']

remote_write:
  # yamllint disable-line rule:line-length
  - url: "http://portal_influxdb:8086/api/v1/prom/write?db=portal_prometheus&u=prometheus&p=secret"

remote_read:
  # yamllint disable-line rule:line-length
  - url: "http://portal_influxdb:8086/api/v1/prom/read?db=portal_prometheus&u=prometheus&p=secret"
